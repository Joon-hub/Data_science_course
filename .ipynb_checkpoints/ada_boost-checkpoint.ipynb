{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "data = df.head(10)\n",
    "X = data[iris.feature_names]\n",
    "y = data['target']\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Number of iterations\n",
    "n_iterations = 7  \n",
    "ada = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=n_iterations, algorithm=\"SAMME\", random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Initialize weights\n",
    "sample_weights = np.ones(len(X_train)) / len(X_train)\n",
    "sample_weights_list = [sample_weights.copy()]\n",
    "\n",
    "for i, estimator in enumerate(ada.estimators_):\n",
    "    # Calculate predictions\n",
    "    predictions = estimator.predict(X_train)\n",
    "    incorrect = (predictions != y_train)\n",
    "    \n",
    "    # Calculate estimator error\n",
    "    estimator_error = np.mean(np.average(incorrect, weights=sample_weights, axis=0))\n",
    "    if estimator_error == 0:\n",
    "        break\n",
    "    \n",
    "    # Calculate alpha\n",
    "    alpha = 0.5 * np.log((1 - estimator_error) / max(estimator_error, 1e-10))\n",
    "    \n",
    "    # Update weights\n",
    "    sample_weights *= np.exp(alpha * incorrect * ((sample_weights > 0) | (alpha < 0)))\n",
    "    sample_weights /= np.sum(sample_weights)\n",
    "    sample_weights_list.append(sample_weights.copy())\n",
    "    \n",
    "    # Print weights\n",
    "    print(f\"Iteration {i+1}, Weights:\")\n",
    "    for idx, weight in enumerate(sample_weights):\n",
    "        print(f\"Sample {idx + 1}: {weight:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f2295",
   "metadata": {},
   "source": [
    "**3. Train and Evaluate Models:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
